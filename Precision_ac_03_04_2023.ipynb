{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "2Z1kM3BFUFU2",
        "mVElfNgUVE9f"
      ],
      "mount_file_id": "12htUeP9gpWOZlQwdhWqjhj2pmISeuNyL",
      "authorship_tag": "ABX9TyP9qdJuib4X7C16uxJa/d4w",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/osv982/Get_the_diff_between_images/blob/main/Precision_ac_03_04_2023.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# U-Net Image Segmentation\n"
      ],
      "metadata": {
        "id": "z37RtHyxT8dW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setup\n"
      ],
      "metadata": {
        "id": "2Z1kM3BFUFU2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import cv2\n",
        "from glob import glob\n",
        "import tensorflow as tf\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.layers import *\n",
        "from keras.models import Model\n",
        "from tqdm import tqdm\n",
        "from keras.utils import CustomObjectScope\n",
        "from datetime import datetime\n",
        "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau, CSVLogger, TensorBoard"
      ],
      "metadata": {
        "id": "fy30EyiLUHct"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data"
      ],
      "metadata": {
        "id": "mpTJ0pYtUwyf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def load_data(path, split=0.2):\n",
        "    ## 60-20-20\n",
        "    images = sorted(glob(os.path.join(path, \"images/*\")))\n",
        "    masks = sorted(glob(os.path.join(path, \"masks/*\")))\n",
        "\n",
        "    total_size = len(images)\n",
        "    # valid_size = int(split * total_size)\n",
        "    # test_size = int(split * total_size)\n",
        "\n",
        "    valid_size = int(0.0002* total_size)\n",
        "    test_size = int(0.9998* total_size)\n",
        "\n",
        "    print(f'total_size {total_size} valid_size {valid_size} test_size {test_size}')\n",
        "    # y - маска x - изображение\n",
        "    train_x, valid_x = train_test_split(images, test_size=valid_size, random_state=42)\n",
        "    train_y, valid_y = train_test_split(masks, test_size=valid_size, random_state=42)\n",
        "\n",
        "    train_x, test_x = train_test_split(train_x, test_size=test_size, random_state=42)\n",
        "    train_y, test_y = train_test_split(train_y, test_size=test_size, random_state=42)\n",
        "\n",
        "    return (train_x, train_y), (valid_x, valid_y), (test_x, test_y)\n",
        "\n",
        "def read_image(path):\n",
        "    path = path.decode()\n",
        "    x = cv2.imread(path, cv2.IMREAD_COLOR)\n",
        "    # x = cv2.resize(x, (256, 256))\n",
        "    x = x/255.0\n",
        "    return x\n",
        "\n",
        "def read_mask(path):\n",
        "    path = path.decode()\n",
        "    x = cv2.imread(path, cv2.IMREAD_COLOR)\n",
        "    x = x/255.0\n",
        "    return x\n",
        "\n",
        "def tf_parse(x, y):\n",
        "    def _parse(x, y):\n",
        "        x = read_image(x)\n",
        "        y = read_mask(y)\n",
        "        return x, y\n",
        "    x, y = tf.numpy_function(_parse, [x, y], [tf.float64, tf.float64])\n",
        "    x.set_shape([128, 128, 3])\n",
        "    y.set_shape([128, 128, 3])\n",
        "    return x, y\n",
        "\n",
        "def tf_dataset(x, y, batch=8):\n",
        "    dataset = tf.data.Dataset.from_tensor_slices((x, y))\n",
        "    dataset = dataset.map(tf_parse)\n",
        "    dataset = dataset.batch(batch)\n",
        "    dataset = dataset.repeat()\n",
        "    return dataset\n"
      ],
      "metadata": {
        "id": "uZ_RuoV-Uz8m"
      },
      "execution_count": 89,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "    path = 'drive/MyDrive/dataset_image/CVC-612'\n",
        "    (train_x, train_y), (valid_x, valid_y), (test_x, test_y) = load_data(path)\n",
        "    print(len(train_x), len(valid_x), len(test_x))\n",
        "\n",
        "    ds = tf_dataset(test_x,test_y)\n",
        "    for x,y in ds:\n",
        "        print(x.shape, y.shape)\n",
        "        break"
      ],
      "metadata": {
        "id": "YguyNwh4lfAF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8ebaa43c-df99-4fb4-935c-26b176858741"
      },
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total_size 6084 valid_size 1 test_size 6082\n",
            "1 1 6082\n",
            "(8, 128, 128, 3) (8, 128, 128, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model"
      ],
      "metadata": {
        "id": "_SYJLImJU5c_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def conv_block(x, num_filters):\n",
        "    x = Conv2D(num_filters, (3, 3), padding=\"same\")(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation(\"relu\")(x)\n",
        "\n",
        "    x = Conv2D(num_filters, (3, 3), padding=\"same\")(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation(\"relu\")(x)\n",
        "\n",
        "    return x\n",
        "\n",
        "def build_model():\n",
        "    size = 128\n",
        "    num_filters = [8, 16, 32, 48]\n",
        "    inputs = Input((size, size, 3))\n",
        "\n",
        "    skip_x = []\n",
        "    x = inputs\n",
        "    ## Encoder\n",
        "    for f in num_filters:\n",
        "        x = conv_block(x, f)\n",
        "        skip_x.append(x)\n",
        "        x = MaxPool2D((2, 2))(x)\n",
        "\n",
        "    ## Bridge\n",
        "    x = conv_block(x, num_filters[-1])\n",
        "\n",
        "    num_filters.reverse()\n",
        "    skip_x.reverse()\n",
        "    ## Decoder\n",
        "    for i, f in enumerate(num_filters):\n",
        "        x = UpSampling2D((2, 2))(x)\n",
        "        xs = skip_x[i]\n",
        "        x = Concatenate()([x, xs])\n",
        "        x = conv_block(x, f)\n",
        "\n",
        "    ## Output\n",
        "    x = Conv2D(3, (1, 1), padding=\"same\")(x)\n",
        "    x = Activation(\"softmax\")(x)\n",
        "    # было изменено с sigmoid на softmax\n",
        "\n",
        "    return Model(inputs, x)"
      ],
      "metadata": {
        "id": "yDvWiP56VDFm"
      },
      "execution_count": 91,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = build_model()\n",
        "model.summary()\n",
        "# for i in dir(model):\n",
        "#   print(i,'\\n')\n",
        "# model.losses\n"
      ],
      "metadata": {
        "id": "yxFA96lPluh3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train"
      ],
      "metadata": {
        "id": "mVElfNgUVE9f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def iou(y_true, y_pred):\n",
        "    def f(y_true, y_pred):\n",
        "        intersection = (y_true * y_pred).sum()\n",
        "        union = y_true.sum() + y_pred.sum() - intersection\n",
        "        x = (intersection + 1e-15) / (union + 1e-15)\n",
        "        x = x.astype(np.float32)\n",
        "        return x\n",
        "    return tf.numpy_function(f, [y_true, y_pred], tf.float32)"
      ],
      "metadata": {
        "id": "cvPt_jsgVGts"
      },
      "execution_count": 93,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "path = 'drive/MyDrive/dataset_image/CVC-612'\n",
        "\n",
        "(train_x, train_y), (valid_x, valid_y), (test_x, test_y) = load_data(path)\n",
        "print(len(train_x), len(valid_x), len(test_x))\n",
        "\n",
        "## Hyperparameters\n",
        "batch = 8\n",
        "lr = 1e-4\n",
        "epochs = 20\n",
        "\n",
        "train_dataset = tf_dataset(train_x, train_y, batch=batch)\n",
        "valid_dataset = tf_dataset(valid_x, valid_y, batch=batch)\n",
        "\n",
        "print(valid_dataset)\n",
        "\n",
        "model = build_model()\n",
        "\n",
        "opt = tf.keras.optimizers.Adam(lr)\n",
        "# metrics = [\"acc\", tf.keras.metrics.Recall(), tf.keras.metrics.Precision(), iou]\n",
        "# model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=opt, metrics=metrics)\n",
        "\n",
        "loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "metrics = ['accuracy']\n",
        "model.compile(loss=\"categorical_crossentropy\", optimizer=opt, metrics=metrics)\n",
        "\n",
        "# log_dir = \"out_log\"\n",
        "\n",
        "callbacks = [\n",
        "    ModelCheckpoint(\"files/model.h5\"),\n",
        "    ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=4),\n",
        "    CSVLogger(\"files/data.csv\"),\n",
        "    # TensorBoard(log_dir=log_dir, histogram_freq=1),\n",
        "    # TensorBoard(log_dir=log_dir, histogram_freq=1),\n",
        "    EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=False)\n",
        "]\n",
        "\n",
        "train_steps = len(train_x)//batch\n",
        "valid_steps = len(valid_x)//batch\n",
        "\n",
        "if len(train_x) % batch != 0:\n",
        "    train_steps += 1\n",
        "if len(valid_x) % batch != 0:\n",
        "    valid_steps += 1\n",
        "\n",
        "model.fit(train_dataset,\n",
        "    validation_data=valid_dataset,\n",
        "    epochs=epochs,\n",
        "    steps_per_epoch=train_steps,\n",
        "    validation_steps=valid_steps,\n",
        "    callbacks=callbacks,\n",
        "    shuffle = False)"
      ],
      "metadata": {
        "id": "4BvDef6DlyZm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Predict"
      ],
      "metadata": {
        "id": "zb5mqHtxVgcT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def read_image(path):\n",
        "    x = cv2.imread(path, cv2.IMREAD_COLOR)\n",
        "    x = x/255.0\n",
        "    return x\n",
        "\n",
        "def read_mask(path):\n",
        "    x = cv2.imread(path, cv2.IMREAD_COLOR)\n",
        "    x = x / 255.0\n",
        "    return x\n",
        "\n",
        "def mask_parse(mask):\n",
        "    # print(f'mask 1_1 shape{mask.shape}\\n{mask}')\n",
        "    mask = np.squeeze(mask)\n",
        "    # print(f'mask 1_2 shape{mask.shape}\\n{mask}')\n",
        "    # mask = [mask, mask, mask]\n",
        "    # print(f'mask 1_3 {mask}')\n",
        "    # mask = np.transpose(mask, (1, 2, 0))\n",
        "    # print(f'mask 1_4 {mask}')\n",
        "    return mask"
      ],
      "metadata": {
        "id": "y69pvdxrVlrk"
      },
      "execution_count": 94,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Dataset\n",
        "path = 'drive/MyDrive/dataset_image/CVC-612'\n",
        "path2model = 'drive/MyDrive/dataset_image/model.h5'\n",
        "batch_size = 8\n",
        "(train_x, train_y), (valid_x, valid_y), (test_x, test_y) = load_data(path)\n",
        "\n",
        "test_dataset = tf_dataset(test_x, test_y, batch=batch_size)\n",
        "\n",
        "test_steps = (len(test_x)//batch_size)\n",
        "if len(test_x) % batch_size != 0:\n",
        "    test_steps += 1\n",
        "\n",
        "with CustomObjectScope({'iou': iou}):\n",
        "    model = tf.keras.models.load_model(path2model)\n",
        "\n",
        "# print(test_dataset)\n",
        "# print('\\n\\n model losses\\n\\n',model.losses)\n",
        "# model.evaluate(test_dataset, steps=test_steps)\n",
        "\n",
        "for i, (x, y) in tqdm(enumerate(zip(test_x, test_y)), total=len(test_x)):\n",
        "    name, exp = os.path.splitext(str(x))\n",
        "    im_sz = name.split('_')[2:]\n",
        "    im_sz = im_sz[0]+'_'+im_sz[1]\n",
        "\n",
        "    # print(im_sz)\n",
        "    # print(x)\n",
        "    # print(y)\n",
        "    x = read_image(x)\n",
        "    y = read_mask(y)\n",
        "    y_pred = model.predict(np.expand_dims(x, axis=0))\n",
        "    h, w, _ = x.shape\n",
        "\n",
        "    white_line = np.ones((h, 10, 3)) * 255.0\n",
        "\n",
        "    # all_images = [\n",
        "    #     x * 255.0, white_line,\n",
        "    #     y * 255.0, white_line,\n",
        "    #     mask_parse(y_pred) * 255.0\n",
        "    # ]\n",
        "    # image = np.concatenate(all_images, axis=1)\n",
        "    image = mask_parse(y_pred) * 255.0\n",
        "\n",
        "    res = cv2.imwrite(f\"drive/MyDrive/dataset_image/CVC-612/result/{im_sz}.png\", image)\n",
        " \n"
      ],
      "metadata": {
        "id": "ZFVSyov8l_tA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "\n",
        "ext = '.png'\n",
        "\n",
        "start_img = ''\n",
        "main_img =''\n",
        "\n",
        "w, h, c = (10000, 10000, 3)\n",
        "d = 128\n",
        "\n",
        "for i in range(0, h - h % d, d):\n",
        "    for j in range(0, w - w % d, d):\n",
        "        fname = os.path.join('drive/MyDrive/dataset_image/CVC-612/result', f'{i}_{j}{ext}')\n",
        "        if os.path.isfile(fname):\n",
        "            if j == 0:\n",
        "                start_img = cv2.imread(fname)\n",
        "            else:\n",
        "                temp_img = cv2.imread(fname)\n",
        "                start_img = cv2.hconcat([start_img, temp_img])\n",
        "        else:\n",
        "            print(f'File {fname} is not exist')\n",
        "            empty_img = np.zeros([128, 128, 3], dtype=np.uint8)\n",
        "            empty_img.fill(255)\n",
        "            start_img = cv2.hconcat([start_img, empty_img])\n",
        "\n",
        "    if i == 0:\n",
        "        main_img = start_img\n",
        "    else:\n",
        "        main_img = cv2.vconcat([main_img, start_img])\n",
        "\n",
        "filename = os.path.join('drive/MyDrive/dataset_image/CVC-612', f'sum_img_1{ext}')\n",
        "cv2.imwrite(filename, main_img)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6SvP0rAeF-l6",
        "outputId": "ada68ee4-4df4-46ce-c7d8-8ba24ddeeb01"
      },
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "File drive/MyDrive/dataset_image/CVC-612/result/2432_4608.png is not exist\n",
            "File drive/MyDrive/dataset_image/CVC-612/result/3840_2560.png is not exist\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 99
        }
      ]
    }
  ]
}